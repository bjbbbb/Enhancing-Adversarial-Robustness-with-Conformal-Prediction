Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability

This project introduces an innovative approach to enhancing the robustness and reliability of deep learning models, particularly for high-risk applications. By integrating adversarial training with Conformal Prediction (CP), we formulate a bi-level optimization framework where an attacker and a defender engage in a strategic battle to respectively maximize and minimize model uncertainty.

For the CIFAR-10 and CIFAR-100 datasets, a recommendation of $5$ base training epochs is suggested. For the ImageNetMini dataset, a recommendation of $10$ base training epochs is suggested.

If you find our article helpful to you, please cite the following article:

@inproceedings{bao2025enhancing,

  title={Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability},
  
  year={2025},
  
  author={Bao, Jie and Dang, Chuangyin and Luo, Rui and Zhang, Hanwei and Zhou, Zhixin},
  
  booktitle={Proceedings of the Forty-second International Conference on Machine Learning (ICML)}
  
}
